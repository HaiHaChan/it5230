{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse \n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "class MF(object):\n",
    "    def __init__(self, Y, k, X = None, W = None, lamda = 0.1,\n",
    "                dist_func = cosine_similarity, learning_rate = 0.5, max_iter = 1000, user_based = 1, limit = 10):\n",
    "#         self.f = open('danhgiaMF.dat', 'a+')\n",
    "        self.Y = Y\n",
    "        self.lamda = lamda\n",
    "        self.k = k\n",
    "        self.dist_func = dist_func\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.user_based = user_based\n",
    "        self.limit = limit\n",
    "        self.users_count = int(np.max(self.Y[:, 0])) + 1\n",
    "        self.items_count = int(np.max(self.Y[:, 1])) + 1\n",
    "        self.ratings_count = Y.shape[0]\n",
    "        if X == None:\n",
    "            self.X = np.random.randn(self.items_count, k)\n",
    "        if W == None:\n",
    "            self.W = np.random.randn(k, self.users_count)\n",
    "        self.Ybar = self.Y.copy()\n",
    "        \n",
    "    def normalizeY(self):\n",
    "        if self.user_based:\n",
    "            user_col = 0\n",
    "            item_col = 1\n",
    "            n_objects = self.users_count\n",
    "        else:\n",
    "            user_col = 1\n",
    "            item_col = 0 \n",
    "            n_objects = self.items_count\n",
    "        users = self.Y[:, user_col]\n",
    "        self.mu = np.zeros((n_objects,))\n",
    "        for i in range(n_objects):\n",
    "            ids = np.where(users == i)[0].astype(int)\n",
    "            ratings = self.Y[ids, 2]\n",
    "            m = np.mean(ratings)\n",
    "            if np.isnan(m):\n",
    "                m = 0\n",
    "            self.mu[i] = m\n",
    "            self.Ybar[ids, 2] = ratings - self.mu[i]\n",
    "#         print(self.Ybar)\n",
    "    \n",
    "    def get_user_rated_item(self, i):\n",
    "        ids = np.where(i == self.Ybar[:, 1])[0].astype(int)\n",
    "        users = self.Ybar[ids, 0].astype(int)\n",
    "        ratings = self.Ybar[ids, 2]\n",
    "        \n",
    "        return (users, ratings)\n",
    "        \n",
    "\n",
    "    def get_item_rated_by_user(self, u):\n",
    "        ids = np.where(u == self.Ybar[:, 0])[0].astype(int)\n",
    "        items = self.Ybar[ids, 1].astype(int)\n",
    "        ratings = self.Ybar[ids, 2]\n",
    "        \n",
    "        return (items, ratings)\n",
    "    \n",
    "    def updateX(self):\n",
    "        for i in range(self.items_count):\n",
    "            users, ratings = self.get_user_rated_item(i)\n",
    "            Wi = self.W[:, users]\n",
    "            a = -(ratings - self.X[i, :].dot(Wi)).dot(Wi.T)/self.ratings_count + \\\n",
    "            self.lamda*self.X[i, :]\n",
    "            self.X[i, :] -= self.learning_rate*(a).reshape((self.k,))\n",
    "        \n",
    "    def updateW(self):\n",
    "        for u in range(self.users_count):\n",
    "            items, ratings = self.get_item_rated_by_user(u)\n",
    "            Xn = self.X[items, :]\n",
    "            a = -Xn.T.dot(ratings - Xn.dot(self.W[:, u]))/self.ratings_count + self.lamda*self.W[:, u]\n",
    "            self.W[:, u] -= self.learning_rate*(a).reshape((self.k,))\n",
    "        \n",
    "    def fit(self, x, data_size, Data_test, test_size = 0):\n",
    "        self.normalizeY()\n",
    "        for i in range(self.max_iter):\n",
    "            self.updateX()\n",
    "            self.updateW()\n",
    "            if (i + 1) % x == 0:\n",
    "                print(i + 1)\n",
    "                self.RMSE(data_size, Data_test, test_size = 0)\n",
    "                self.evaluate(data_size, Data_test, test_size = 0)\n",
    "            \n",
    "    def pred(self, u, i):\n",
    "        u = int(u)\n",
    "        i = int(i)\n",
    "        if self.user_based:\n",
    "            bias = self.mu[u]\n",
    "        else: \n",
    "            bias = self.mu[i]\n",
    "        pred = self.X[i, :].dot(self.W[:, u]) + bias\n",
    "        \n",
    "        if pred < 1:\n",
    "            return 1 \n",
    "        if pred > 5: \n",
    "            return 5 \n",
    "        return pred\n",
    "    \n",
    "    def recommend(self, u):\n",
    "        ids = np.where(self.Y[:, 0] == u)[0].astype(int)\n",
    "        items_rated_by_user = self.Y[ids, 1].tolist()\n",
    "        if self.user_based:\n",
    "            bias = self.mu[u]\n",
    "        else: \n",
    "            bias = self.mu[i]\n",
    "        pred = self.X.dot(self.W[:, u]) + bias\n",
    "        a = np.zeros((self.items_count,))\n",
    "        recommended_items = []\n",
    "        for i in range(self.items_count):\n",
    "            if i not in items_rated_by_user:\n",
    "                a[i] = pred[i]\n",
    "        if len(a) < self.limit:\n",
    "            recommended_items = np.argsort(a)[-self.items_count:]\n",
    "        else:\n",
    "            recommended_items = np.argsort(a)[-self.limit:]\n",
    "        recommended_items = np.where(a[:] > 0)[0].astype(int)\n",
    "\n",
    "#         return random.sample(list(recommended_items), self.limit)\n",
    "        return recommended_items[:self.limit]\n",
    "#         return recommended_items\n",
    "    \n",
    "    def RMSE(self, data_size, Data_test, test_size = 0):\n",
    "        n_tests = Data_test.shape[0]\n",
    "        SE = 0\n",
    "        for n in range(n_tests):\n",
    "            pred = self.pred(Data_test[n, 0], Data_test[n, 1])\n",
    "            SE += (pred - Data_test[n, 2])**2 \n",
    "\n",
    "        RMSE = np.sqrt(SE/n_tests)\n",
    "        print('RMSE =', RMSE)\n",
    "        if self.user_based:\n",
    "            print('%s::1::%d::%d::cosine_similarity::%r::%r\\r\\n' % (str(data_size), self.k, self.max_iter, test_size, RMSE))\n",
    "#             self.f.write('%s::1::%d::cosine_similarity::%r::%r\\r\\n' % (str(data_size), self.k,self.max_iter, test_size, RMSE))\n",
    "        else:\n",
    "            print('%s::0::%d::%d::cosine_similarity::%r::%r\\r\\n' % (str(data_size), self.k, self.max_iter, test_size, RMSE))\n",
    "#             self.f.write('%s::0::%d::cosine_similarity::%r::%r\\r\\n' % (str(data_size), self.k, test_size, RMSE))\n",
    "#         self.f.close()\n",
    "    \n",
    "    def evaluate(self, data_size, Data_test, test_size = 0):\n",
    "        sum_p = 0\n",
    "        sum_r = 0\n",
    "        self.Pu = np.zeros((self.users_count,))\n",
    "        for u in range(self.users_count):\n",
    "            recommended_items = self.recommend(u)\n",
    "            ids = np.where(Data_test[:, 0] == u)[0]\n",
    "            rated_items = Data_test[ids, 1]\n",
    "            for i in rated_items:\n",
    "                if i in recommended_items:\n",
    "                    self.Pu[u] += 1\n",
    "                if Data_test[i, 2] > 3:\n",
    "                    sum_r += 1\n",
    "            sum_p += self.Pu[u]\n",
    "        \n",
    "        p = sum_p/(self.users_count * self.limit)\n",
    "        r = sum_p/sum_r\n",
    "        print('%s::0::%d::%d::cosine_similarity::%r::%r::%r\\r\\n' % (str(data_size), self.k, self.max_iter, test_size, p, r))\n",
    "        return p, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse \n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "class MF2(object):\n",
    "    def __init__(self, Y, n_factors = 2, X = None, W = None, lamda = 0.1, lr = 2, n_epochs = 50, user_based = 1, \n",
    "                 limit = 10):\n",
    "        self.f = open('RMSE_18.dat', 'a+')\n",
    "        self.Y = Y\n",
    "        self.lamda = lamda\n",
    "        self.n_factors = n_factors\n",
    "        self.lr = lr\n",
    "        self.n_epochs = n_epochs\n",
    "        self.user_based = user_based\n",
    "        self.limit = limit\n",
    "        self.users_count = int(np.max(self.Y[:, 0])) + 1\n",
    "        self.items_count = int(np.max(self.Y[:, 1])) + 1\n",
    "        self.ratings_count = Y.shape[0]\n",
    "        if X == None:\n",
    "            self.X = np.random.randn(self.items_count, n_factors)\n",
    "        if W == None:\n",
    "            self.W = np.random.randn(n_factors, self.users_count)\n",
    "        self.Ybar = self.Y.copy()\n",
    "        \n",
    "        self.bi = np.random.randn(self.items_count)\n",
    "        self.bu = np.random.randn(self.users_count)\n",
    "        self.n_ratings = self.Y.shape[0]\n",
    "        \n",
    "    def normalizeY(self):\n",
    "        if self.user_based:\n",
    "            user_col = 0\n",
    "            item_col = 1\n",
    "            n_objects = self.users_count\n",
    "        else:\n",
    "            user_col = 1\n",
    "            item_col = 0 \n",
    "            n_objects = self.items_count\n",
    "        users = self.Y[:, user_col]\n",
    "        self.mu = np.zeros((n_objects,))\n",
    "        for i in range(n_objects):\n",
    "            ids = np.where(users == i)[0].astype(int)\n",
    "            ratings = self.Y[ids, 2]\n",
    "            m = np.mean(ratings)\n",
    "            if np.isnan(m):\n",
    "                m = 0\n",
    "#             self.mu[i] = m\n",
    "            self.Ybar[ids, 2] = ratings - self.mu[i]\n",
    "#         print(self.Ybar)\n",
    "    \n",
    "    def get_user_rated_item(self, i):\n",
    "        ids = np.where(i == self.Ybar[:, 1])[0].astype(int)\n",
    "        users = self.Ybar[ids, 0].astype(int)\n",
    "        ratings = self.Ybar[ids, 2]\n",
    "        \n",
    "        return (users, ratings)\n",
    "        \n",
    "\n",
    "    def get_item_rated_by_user(self, u):\n",
    "        ids = np.where(u == self.Ybar[:, 0])[0].astype(int)\n",
    "        items = self.Ybar[ids, 1].astype(int)\n",
    "        ratings = self.Ybar[ids, 2]\n",
    "        \n",
    "        return (items, ratings)\n",
    "    \n",
    "    def updateX(self):\n",
    "        for m in range(self.items_count):\n",
    "            users, ratings = self.get_user_rated_item(m)\n",
    "            Wm = self.W[:, users]\n",
    "            b = self.bu[users]\n",
    "            sum_grad_xm = np.full(shape = (self.X[m].shape) , fill_value = 1e-8)\n",
    "            sum_grad_bm = 1e-8\n",
    "            for i in range(50):\n",
    "                xm = self.X[m]\n",
    "                error = xm.dot(Wm) + self.bi[m] + b - ratings\n",
    "                grad_xm = error.dot(Wm.T)/self.n_ratings + self.lamda*xm\n",
    "                grad_bm = np.sum(error)/self.n_ratings\n",
    "                sum_grad_xm += grad_xm**2\n",
    "                sum_grad_bm += grad_bm**2\n",
    "                # gradient descent\n",
    "                self.X[m] -= self.lr*grad_xm.reshape(-1)/np.sqrt(sum_grad_xm)\n",
    "                self.bi[m] -= self.lr*grad_bm/np.sqrt(sum_grad_bm)\n",
    "        \n",
    "    def updateW(self):\n",
    "        for n in range(self.users_count):\n",
    "            items, ratings = self.get_item_rated_by_user(n)\n",
    "            Xn = self.X[items, :]\n",
    "            b = self.bi[items]\n",
    "            sum_grad_wn = np.full(shape = (self.W[:, n].shape) , fill_value = 1e-8).T\n",
    "            sum_grad_bn = 1e-8\n",
    "            for i in range(50):\n",
    "                wn = self.W[:, n]\n",
    "                error = Xn.dot(wn) + self.bu[n] + b - ratings\n",
    "                grad_wn = Xn.T.dot(error)/self.n_ratings + self.lamda*wn\n",
    "                grad_bn = np.sum(error)/self.n_ratings\n",
    "                sum_grad_wn += grad_wn**2\n",
    "                sum_grad_bn += grad_bn**2\n",
    "                # gradient descent\n",
    "                self.W[:, n] -= self.lr*grad_wn.reshape(-1)/np.sqrt(sum_grad_wn)\n",
    "                self.bu[n] -= self.lr*grad_bn/np.sqrt(sum_grad_bn)\n",
    "\n",
    "    def fit(self, x, data_size, Data_test, test_size = 0):\n",
    "        self.normalizeY()\n",
    "        for i in range(self.n_epochs):\n",
    "            self.updateW()\n",
    "            self.updateX()\n",
    "            if (i + 1) % x == 0:\n",
    "#                 print(i + 1)\n",
    "                self.RMSE(Data_test,data_size = data_size, test_size = 0, p = i+1)\n",
    "#                 self.evaluate(data_size, Data_test, test_size = 0)\n",
    "            \n",
    "    def pred(self, u, i):\n",
    "        u = int(u)\n",
    "        i = int(i)\n",
    "        if self.user_based:\n",
    "            bias = self.mu[u]\n",
    "        else: \n",
    "            bias = self.mu[i]\n",
    "        pred = self.X[i, :].dot(self.W[:, u]) + self.bi[i] + self.bu[u] + bias\n",
    "        \n",
    "        if pred < 1:\n",
    "            return 1 \n",
    "        if pred > 5: \n",
    "            return 5 \n",
    "        return max(0, min(5, pred))\n",
    "    \n",
    "    def recommend(self, u):\n",
    "        ids = np.where(self.Y[:, 0] == u)[0].astype(int)\n",
    "        items_rated_by_user = self.Y[ids, 1].tolist()\n",
    "        a = np.zeros((self.items_count,))\n",
    "        recommended_items = []\n",
    "        pred = self.X.dot(self.W[:, u])\n",
    "        for i in range(self.items_count):\n",
    "            if i not in items_rated_by_user:\n",
    "                if self.user_based:\n",
    "                    bias = self.mu[u]\n",
    "                else: \n",
    "                    bias = self.mu[i]\n",
    "                a[i] = pred[i] +self.bi[i] + self.bu[u] + bias\n",
    "        if len(a) < self.limit:\n",
    "            recommended_items = np.argsort(a)[-self.items_count:]\n",
    "        else:\n",
    "            recommended_items = np.argsort(a)[-self.limit:]\n",
    "        recommended_items = np.where(a[:] > 0)[0].astype(int)\n",
    "\n",
    "#         return random.sample(list(recommended_items), self.limit)\n",
    "        return recommended_items[:self.limit]\n",
    "#         return recommended_items\n",
    "    \n",
    "    def RMSE(self, Data_test, test_size = 0, data_size = '100K', p = 10):\n",
    "        n_tests = Data_test.shape[0]\n",
    "        SE = 0\n",
    "        for n in range(n_tests):\n",
    "            pred = self.pred(Data_test[n, 0], Data_test[n, 1])\n",
    "            SE += (pred - Data_test[n, 2])**2 \n",
    "\n",
    "        RMSE = np.sqrt(SE/n_tests)\n",
    "#         print('RMSE =', RMSE)\n",
    "        if self.user_based:\n",
    "            print('%s::1::%d::%d::%r::%r::%r\\r\\n' % (str(data_size), self.n_factors, self.n_epochs, self.lamda, self.lr, RMSE))\n",
    "            self.f.write('%s::1::%d::%d::%d::%r::%r::%r\\r\\n' % (str(data_size), self.n_factors, self.n_epochs, p, self.lamda, self.lr, RMSE))\n",
    "        else:\n",
    "            print('%s::0::%d::%d::cosine_similarity::%r::%r\\r\\n' % (str(data_size), self.n_factors, self.n_epochs, test_size, RMSE))\n",
    "            self.f.write('%s::0::%d::cosine_similarity::%r::%r\\r\\n' % (str(data_size), self.n_factors, test_size, RMSE))\n",
    "#         self.f.close()\n",
    "        return RMSE\n",
    "    \n",
    "    def evaluate(self, data_size, Data_test, test_size = 0):\n",
    "        sum_p = 0\n",
    "        sum_r = 0\n",
    "        self.Pu = np.zeros((self.users_count,))\n",
    "        for u in range(self.users_count):\n",
    "            recommended_items = self.recommend(u)\n",
    "            ids = np.where(Data_test[:, 0] == u)[0]\n",
    "            rated_items = Data_test[ids, 1]\n",
    "            for i in recommended_items:\n",
    "                if i in rated_items:\n",
    "                    self.Pu[u] += 1\n",
    "            sum_p += self.Pu[u]\n",
    "        print('sump', sum_p, sum_r)\n",
    "        p = sum_p/(self.users_count * self.limit)\n",
    "        r = sum_p/(Data_test.shape[0])\n",
    "        self.f.write('%s::1::%d::%d::%d::cosine_similarity::%r::%r::%r\\r\\n' % (str(data_size), self.limit, self.n_factors, self.n_epochs, test_size, p, r))\n",
    "        return p, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestemp']\n",
    "\n",
    "ratings_base_1 = pd.read_csv('ml-100k/ua.base', sep='\\t', names=r_cols, encoding='latin-1', engine='python')\n",
    "ratings_test_1 = pd.read_csv('ml-100k/ua.test', sep='\\t', names=r_cols, encoding='latin-1', engine='python')\n",
    "\n",
    "ratings_matrix_1 = ratings_base_1.as_matrix()\n",
    "ratings_matrix = ratings_test_1.as_matrix()\n",
    "\n",
    "ratings_matrix_1[:, :2] -= 1\n",
    "ratings_matrix[:, :2] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100K::1::2::5::0.01::0.1::0.9631156547867717\n",
      "\n",
      "100K::1::4::5::0.01::0.1::0.962939553365153\n",
      "\n",
      "100K::1::6::5::0.01::0.1::0.9627534130951362\n",
      "\n",
      "100K::1::8::5::0.01::0.1::0.963092590361273\n",
      "\n",
      "100K::1::10::5::0.01::0.1::0.9632294094042084\n",
      "\n",
      "100K::1::12::5::0.01::0.1::0.9631922477170105\n",
      "\n",
      "100K::1::14::5::0.01::0.1::0.9636886015167433\n",
      "\n",
      "100K::1::16::5::0.01::0.1::0.9633370667605006\n",
      "\n",
      "100K::1::18::5::0.01::0.1::0.9631848953071165\n",
      "\n",
      "100K::1::20::5::0.01::0.1::0.9626363026922741\n",
      "\n",
      "100K::1::22::5::0.01::0.1::0.9630374363120899\n",
      "\n",
      "100K::1::24::5::0.01::0.1::0.9630991482806758\n",
      "\n",
      "100K::1::26::5::0.01::0.1::0.9634383624486857\n",
      "\n",
      "100K::1::28::5::0.01::0.1::0.9627565753781575\n",
      "\n",
      "100K::1::30::5::0.01::0.1::0.9628442995554312\n",
      "\n",
      "100K::1::32::5::0.01::0.1::0.9633906830572753\n",
      "\n",
      "100K::1::34::5::0.01::0.1::0.9631999666857369\n",
      "\n",
      "100K::1::36::5::0.01::0.1::0.962746419275473\n",
      "\n",
      "100K::1::38::5::0.01::0.1::0.9623721661445331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 40, 2):\n",
    "#     for j in np.arange(0.01, 0.51, 0.01) :\n",
    "#         for k in np.arange(0.1, 1.1, 0.1): \n",
    "    rs = MF2(ratings_matrix_1, n_factors = i, lamda = 0.01, lr = 0.1, n_epochs= 5)\n",
    "    rs.fit5, \"1M\", ratings_matrix)\n",
    "    rs.RMSE(data_size='100K', Data_test= ratings_matrix)\n",
    "    rs.f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs = MF2(ratings_matrix_1, n_factors = 5, lamda = 1, lr = 0.5, n_epochs= 2)\n",
    "rs.fit(1, \"100K\", ratings_matrix)\n",
    "for i in range(10, 510, 10):\n",
    "    rs.limit = i\n",
    "    rs.evaluate('100K', ratings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs.f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'item_id', 'rating']\n",
    "ratings = pd.read_csv('ex.dat', sep = ' ', names = r_cols, encoding='latin-1')\n",
    "Y_data = ratings.as_matrix()\n",
    "\n",
    "rs = MF(Y_data, k = 2)\n",
    "\n",
    "rs.fit()\n",
    "rs.pred(6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "r_cols = ['dataset', 'uMF', 'k','dist_func', 'test_size', 'RMSE']\n",
    "\n",
    "RMSEs = pd.read_csv('danhgiaMF.dat', sep='::', names=r_cols, encoding='latin-1', engine='python')\n",
    "\n",
    "rs = RMSEs.as_matrix()\n",
    "print(RMSEs)\n",
    "dataset = rs[:, 0]\n",
    "uMF = rs[:, 1]\n",
    "\n",
    "for n in ['100K', '1M']:\n",
    "    ids_ii = np.where((dataset == n) & (uMF == 0))[0].astype(np.int32)\n",
    "    ids_uu = np.where((dataset == n) & (uMF == 1))[0].astype(np.int32)\n",
    "    items_ii = rs[ids_ii, 5]\n",
    "    items_uu = rs[ids_uu, 5]\n",
    "    t_ii = range(1, ids_ii.shape[0] + 1, 1)\n",
    "    t_uu = range(1, ids_uu.shape[0] + 1, 1)\n",
    "    plt.plot(t_ii, items_ii, 'g^', t_uu, items_uu, 'bs')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "ratings_base = pd.read_csv('mvl_can/1M_train_01.dat', sep=':', names=r_cols, encoding='latin-1')\n",
    "ratings_test = pd.read_csv('mvl_can/1M_test_01.dat', sep=':', names=r_cols, encoding='latin-1')\n",
    "\n",
    "rate_train = ratings_base.as_matrix()\n",
    "rate_test = ratings_test.as_matrix()\n",
    "\n",
    "# # indices start from 0\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1\n",
    "\n",
    "# for i in np.arange(1, 11, 1):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1M::1::50::10::0.1::0.1::0.9089360615023896\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [50, 60]:\n",
    "#     for j in [0.01, 0.1, 0.5, 1]:\n",
    "#         for k in [0.1, 0.5, 0.75, 1, 2]:\n",
    "#             if ((i == 2) and (j > 0.01)) or (i > 2):\n",
    "    rs = MF2(rate_train, n_factors = i, lamda = 0.1, lr = 0.1, n_epochs= 10)\n",
    "    rs.fit(10, data_size = \"1M\", Data_test = rate_test, test_size =0.1)\n",
    "    rs.f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs = MF2(rate_train, n_factors = 2, lamda = 0.1, lr = 0.1, n_epochs= 10)\n",
    "rs.fit(1, data_size = \"1M\", Data_test = rate_test, test_size =0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs.RMSE(rate_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10, 510, 10):\n",
    "    rs.limit = i\n",
    "    rs.evaluate('1M', rate_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs.f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "ratings_base = pd.read_csv('mvl_can/1M_train_01.dat', sep=':', names=r_cols, encoding='latin-1')\n",
    "ratings_test = pd.read_csv('mvl_can/1M_test_01.dat', sep=':', names=r_cols, encoding='latin-1')\n",
    "\n",
    "rate_train = ratings_base.as_matrix()\n",
    "rate_test = ratings_test.as_matrix()\n",
    "\n",
    "# # indices start from 0\n",
    "# rate_train[:, :2] -= 1\n",
    "# rate_test[:, :2] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1M::1::20::100::0.01::0.1::1.207533851152598\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9115742034244511\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087942008751014\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087608132026868\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087456600540572\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087359874449358\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087311146245375\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087296868636203\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087305676747124\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087332836312793\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087370046029261\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.908741195905123\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087455228841205\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087497546483724\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087537837296358\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.908757568082362\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.908761077628628\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087643033808002\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087672488398199\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087699241987377\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087723336604467\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087746376131732\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087765035793184\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087782432429756\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087800101178641\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087813259269184\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087825818065289\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087836189189047\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.9087851496744117\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.908785063329608\n",
      "\n",
      "1M::1::20::100::0.01::0.1::0.908787656708406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for i in [10, 20]:\n",
    "#     for j in [0.01, 0.1, 0.5, 1]:\n",
    "#         for k in [0.1, 0.5, 0.75, 1, 2]:\n",
    "#             if ((j == 0.01) and (k > 0.75)) or i > 0.01:\n",
    "rs = MF2(rate_train, n_factors = 20, lamda = 0.01, lr = 0.1, n_epochs= 100)\n",
    "# rs.n_epochs = 20\n",
    "rs.fit(2, data_size = \"1M\", Data_test = rate_test, test_size =0.3)\n",
    "rs.f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1M::1::20::20::0.01::0.1::1.2280671172174247\n",
    "\n",
    "1M::1::20::20::0.01::0.1::0.9112817745421858\n",
    "\n",
    "1M::1::20::20::0.01::0.1::0.9088134128227997\n",
    "\n",
    "1M::1::20::20::0.01::0.1::0.9087637397571174\n",
    "\n",
    "1M::1::20::20::0.01::0.1::0.9087396027388266\n",
    "\n",
    "1M::1::20::20::0.01::0.1::0.9087231690125587\n",
    "\n",
    "1M::1::20::20::0.01::0.1::0.9087124853793604\n",
    "\n",
    "1M::1::20::20::0.01::0.1::0.9087058724291941\n",
    "\n",
    "1M::1::20::20::0.01::0.1::0.9087021220324306\n",
    "\n",
    "1M::1::20::20::0.01::0.1::0.9087003635475365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs = MF2(rate_train, n_factors = 2, lamda = 0.01, lr = 0.1, n_epochs= 10)\n",
    "rs.fit(1, data_size = \"1M\", Data_test = rate_test, test_size =0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs.RMSE(data_size = '1M', Data_test=rate_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10, 510, 10):\n",
    "    rs.limit = i\n",
    "    rs.evaluate('1M', rate_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs.f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
