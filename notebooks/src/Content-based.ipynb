{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "\n",
    "def get_items_rated_by_user(rate_matrix, user_id):\n",
    "    y = rate_matrix[:,0]\n",
    "    ids = np.where(y == user_id +1)[0]\n",
    "    item_ids = rate_matrix[ids, 1] - 1\n",
    "    scores = rate_matrix[ids, 2]\n",
    "    return (item_ids, scores)\n",
    "\n",
    "class Contentbased:\n",
    "    def __init__(self, Y, X_train, n_users, n_items, lamda = 1):\n",
    "        self.Y = Y\n",
    "        self.lamda = lamda\n",
    "        self.X_train = X_train\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        \n",
    "    def fit(self):\n",
    "        transformer = TfidfTransformer(smooth_idf=True, norm ='l2')\n",
    "        tfidf = transformer.fit_transform(self.X_train.tolist()).toarray()\n",
    "        d = tfidf.shape[1] # data dimension\n",
    "        W = np.zeros((d, self.n_users))\n",
    "        b = np.zeros((1, self.n_users))\n",
    "        for n in range(self.n_users):    \n",
    "            ids, scores = get_items_rated_by_user(self.Y, n)\n",
    "            clf = Ridge(alpha= self.lamda, fit_intercept  = True)\n",
    "            Xhat = tfidf[ids, :]\n",
    "\n",
    "            clf.fit(Xhat, scores) \n",
    "            W[:, n] = clf.coef_\n",
    "            b[0, n] = clf.intercept_\n",
    "        self.Yhat = tfidf.dot(W) + b\n",
    "        \n",
    "    def RMSE(self, Data_test):\n",
    "        se = 0\n",
    "        cnt = 0\n",
    "        for n in range(self.n_users):\n",
    "            ids, scores_truth = get_items_rated_by_user(Data_test, n)\n",
    "            scores_pred = self.Yhat[ids, n]\n",
    "            e = scores_truth - scores_pred \n",
    "            se += (e*e).sum(axis = 0)\n",
    "            cnt += e.size \n",
    "        return np.sqrt(se/cnt)\n",
    "    \n",
    "    def recommend(self, user_id, top):\n",
    "        a = np.zeros((self.n_items,))\n",
    "        recommended_items = []\n",
    "        items_rated_by_user, score = get_items_rated_by_user(self.Y, user_id)\n",
    "        for i in range(self.n_items):\n",
    "            if i not in items_rated_by_user:\n",
    "                a[i] = self.Yhat[i, user_id]\n",
    "        if len(a) < top:\n",
    "            recommended_items = np.argsort(a)[-len(a):]\n",
    "        else:\n",
    "            recommended_items = np.argsort(a)[-top:]\n",
    "        return recommended_items\n",
    "    \n",
    "    def evaluatePR(self, Data_test, top, data_size):\n",
    "        sum_p = 0\n",
    "        Pu = np.zeros((self.n_users,))\n",
    "        for u in range(n_users):\n",
    "            recommended_items = self.recommend(u, top)\n",
    "            ids = np.where(Data_test[:, 0] == u)[0]\n",
    "            rated_items = Data_test[ids, 1]\n",
    "            for i in recommended_items:\n",
    "                if i in rated_items:\n",
    "                    Pu[u] += 1\n",
    "            sum_p += Pu[u]\n",
    "        p = sum_p/(self.n_users * top)\n",
    "        r = sum_p/(Data_test.shape[0] + 1)\n",
    "    #     print(sum_p)\n",
    "        print('%s::%d::%r::%r\\r\\n' % (str(data_size), top, p, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_cols =  ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('ml-100k/u.user', sep='|', names=u_cols,\n",
    " encoding='latin-1')\n",
    "n_users = users.shape[0]\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "ratings_base = pd.read_csv('ml-100k/ua.base', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "ratings_test = pd.read_csv('ml-100k/ua.test', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "\n",
    "rate_train = ratings_base.as_matrix()\n",
    "rate_test = ratings_test.as_matrix()\n",
    "\n",
    "i_cols = ['movie id', 'movie title' ,'release date','video release date', 'IMDb URL', 'unknown', 'Action', 'Adventure',\n",
    " 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    " 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "items = pd.read_csv('ml-100k/u.item', sep='|', names=i_cols, encoding='latin-1')\n",
    "\n",
    "n_items = items.shape[0]\n",
    "\n",
    "X0 = items.as_matrix()\n",
    "X_train_counts = X0[:, -19:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.024520792639543"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = Contentbased(rate_train, X_train_counts, n_users= n_users, n_items = n_items, lamda=7)\n",
    "cb.fit()\n",
    "cb.RMSE(Data_test=rate_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10, 501, 10):\n",
    "    cb.evaluatePR(rate_test, i, '100K')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tran.thi.hai.ha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/tran.thi.hai.ha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    }
   ],
   "source": [
    "u_cols =  ['user_id', 'sex', 'age', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('ml-1m/users.dat', sep='::', names=u_cols,\n",
    " encoding='latin-1')\n",
    "n_users = users.shape[0]\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "ratings_base = pd.read_csv('mvl/1M_train_03.dat', sep=':', names=r_cols, encoding='latin-1')\n",
    "ratings_test = pd.read_csv('mvl/1M_test_03.dat', sep=':', names=r_cols, encoding='latin-1')\n",
    "\n",
    "rate_train = ratings_base.as_matrix()\n",
    "rate_test = ratings_test.as_matrix()\n",
    "\n",
    "i_cols = ['movie id', 'title' ,'year', 'gen']\n",
    "n_items = 3951\n",
    "\n",
    "items = pd.read_csv('ml-1m/movies.dat', sep='::', names=i_cols, encoding='latin-1')\n",
    "X = items.as_matrix()\n",
    "X_train_count = np.full(shape = (n_items, 19), fill_value = 0)\n",
    "\n",
    "genresList = [\n",
    "  \"Action\",\n",
    "  \"Adventure\",\n",
    "  \"Animation\",\n",
    "  \"Children\",\n",
    "  \"Comedy\",\n",
    "  \"Crime\",\n",
    "  \"Documentary\",\n",
    "  \"Drama\",\n",
    "  \"Fantasy\",\n",
    "  \"Film-Noir\",\n",
    "  \"Horror\",\n",
    "  \"Musical\",\n",
    "  \"Mystery\",\n",
    "  \"Romance\",\n",
    "  \"Sci-Fi\",\n",
    "  \"Thriller\",\n",
    "  \"War\",\n",
    "  \"Western\",\n",
    "  \"(no genres listed)\"\n",
    "]\n",
    "\n",
    "def setGenresMatrix(genres):\n",
    "    movieGenresMatrix = []\n",
    "    movieGenresList = genres.split('|')\n",
    "    for x in genresList:\n",
    "        if (x in movieGenresList):\n",
    "            movieGenresMatrix.append(1)\n",
    "        else:\n",
    "            movieGenresMatrix.append(0)\n",
    "    return movieGenresMatrix\n",
    "for i in range(n_items):\n",
    "    X_train_count[i] = setGenresMatrix(X[i+1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0371836405845278"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb2 = Contentbased(rate_train, X_train_count, n_users= n_users, n_items = n_items, lamda=98)\n",
    "cb2.fit()\n",
    "cb2.RMSE(Data_test=rate_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
